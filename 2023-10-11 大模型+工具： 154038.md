### 大模型+工具：

综述论文Tool Learning with Foundation Models

### 存在的问题：

**意图理解**

控制器需要理解用户所给出的自然语言指令，识别其对应的任务目标。意图理解在现实工具学习应用场景中仍存在着诸多挑战：（1）**指令模糊问题**：用户给出的指令很有可能是不精确甚至多义的。（2）**指令多样问题**：用户给出的指令天然具有个性化和多样性。

**工具理解**

控制器使用工具的前提是理解工具的功能与使用方式。人类在学习使用工具时通常会有两种途径，一是从工具的说明书或是教程中学习；二是通过观察其它人使用工具的过程来学习。类似的，现有工具学习工作通常采用两种提示学习技术实现工具理解：零样本提示学习和少样本提示学习。但是提示学习的有效性很大程度上取决于模型能力，而且会受到输入上下文长度的限制。

![img](https://pic1.zhimg.com/80/v2-9bd74527ea21049be8f272bd888a3604_720w.webp)

零样本提示学习描述工具的功能、输入输出格式等，少样本提示学习则通过具体的使用案例来提示模型如何使用对应工具。



**规划与推理**

对于复杂任务，控制器需要具备一定的规划和推理能力，以便将任务拆分成若干子任务。这一过程中的推理能力可以分为两类：**内省推理（Introspective Reasoning）**是指控制器在不涉及与环境交互的情况下，仅根据指令对任务进行推理和规划，无需中间执行结果。这种推理方式侧重于分析任务的本质，通过对指令的理解来生成相应的规划；与之相反，**外省推理（Extrospective Reasoning），**涉及控制器与环境的交互。在这种情况下，控制器会根据先前步骤的执行结果逐步推理并生成规划。这种方式强调了模型的实时调整和适应能力，使得控制器能够在完成任务过程中不断优化规划策略。

![img](https://pic4.zhimg.com/80/v2-13886178a6f742b81a4bf9e876ef1e07_720w.webp)

在完成对复杂任务进行分解之外，控制器还需要利用不同工具完成各个子任务，在该过程中存在一些挑战需要进一步研究。**工具间的协同配合**：为了完成复杂任务，模型不仅需要理解各个工具的功能，还应该理解它们之间的相互作用和依赖关系。这有助于控制器更有效地使用工具，确保任务的顺利完成。**并行执行**：对于彼此不存在依赖关系的子任务，模型需要具有并行执行的能力以提高执行效率。这将有助于在有限的时间内完成更多任务，提高整体性能。**多智能体协作**：复杂任务通常需要多个智能体彼此协作，在这种情况下，每个智能体都具有其独特的能力和专业知识，彼此协作可以实现更高效和有效的问题解决。因此，探索多智能体协作机制对于提升控制器在复杂任务中的表现具有重要意义。 **可泛化的工具学习训练方法**

为了让模型学会使用工具，训练模型也是一种可行的途径。婴儿学习新工具主要有两种方式，一种是观察模仿成人如何使用工具的过程，另一种是依靠自身的探索，摸索出工具的使用方式。受此启发，工具学习的模型训练范式也可以分成两种：

**从演示中学习**：模型模仿人类使用工具，可采用监督学习、半监督学习或自监督学习来实现。

**从反馈中学习**：环境或人类的反馈可以帮助模型理解其行为的结果并调整其行为，据此改进其工具使用策略，从而增强模型的使用工具能力。强化学习便是实现从反馈中学习的一个代表性解决方案。

![img](https://pic1.zhimg.com/80/v2-c79642fb90cbbc4b589fc24b09bb4190_720w.webp)





题目：Ghost in the Minecraft

如何替代强化学习：1.更好的分解子任务：比如LLM分解器接收高级目标，并使用GPT-3.5基于像材料和工具这样的先决条件将其分解为一个子目标树。它递归地使用来自Minecraft维基和配方的文本知识分解子目标，直到没有依赖项为止。

2.规划：对每个子目标子任务进行动作/工具规划，然后得到minecraft环境的反馈（这点倒是强化学习的reward）。规划器使用指令、查询和反馈来创建并迭代修订计划。它将成功的计划存储在文本记忆中，作为未来参考的常见解决方案。

3.LLM Interface（就相当于对环境的观测）

LLM接口执行前一个模块计划的结构化动作作为键盘和鼠标操作。它使用硬编码的脚本，这些脚本针对环境观察来实施动作。执行后，它提供关于成功/失败和库存变化的反馈。规划器使用失败来修正其计划。



**这篇文章有一定的借鉴意义但是想要大幅度借鉴是有困难的因为它有环境自动反馈**





2.Large Language Models as Tool Makers

缺点问题：1.prompt没有很好的利用，没有memory和retrieval框架；

​					2.没有评分器，评价工具执行结果好坏然后优化代码

​					3.不适用序列工具执行任务