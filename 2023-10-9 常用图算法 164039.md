### 异质图神经网络学习笔记

1.图神经网络

2.异质图：包括多种类型的图结构，相应的，同质图只有一种类型的节点和边。

四种典型的图神经网络结构：

1.GraphSAGE：

GCN是一种在图中结合拓扑结构和顶点属性信息学习顶点的embedding表示的方法。然而GCN要求在一个确定的图中去学习顶点的embedding，无法直接泛化到在训练过程没有出现过的顶点，即属于一种直推式(transductive)的学习。

本文介绍的GraphSAGE则是一种能够利用顶点的属性信息高效产生未知顶点embedding的一种归纳式(inductive)学习的框架。

其核心思想是通过学习一个对邻居顶点进行聚合表示的函数来产生目标顶点的embedding向量。

GraphSAGE 是Graph SAmple and aggreGatE的缩写，其运行流程如上图所示，可以分为三个步骤：

1. 对图中每个顶点邻居顶点进行采样

2. 根据聚合函数聚合邻居顶点蕴含的信息

3. 得到图中各顶点的向量表示供下游任务使用

2.GCN：

![image-20230503104438961](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230503104438961.png)

之所以邻接矩阵 **A**要加上一个单位矩阵 **IN** ，是因为我们希望在进行信息传播的时候顶点自身的特征信息也得到保留。

缺点：

​	主要缺点：1.融合时边权值是固定的，不够灵活。2.可扩展性差，因为它是全图卷积融合，全图做梯度更新，当图比较大时，这样的方式就太慢了，不合适。3.GCN 用的是简单的邻居平均的聚合策略，那么叠加多层之后**：节点的表示就丧失了它的局部信息，表示趋于一致，即过平滑现象。**层数加深时，结果会极容易平滑，每个点的特征结果都十分相似。

此外还有一个问题：

![image-20230607163529564](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230607163529564.png)

GAT就来解决问题1的，GraphSAGE就来解决这个问题2的，DeepGCN等一系列文章就来讨论问题3的。基本上，GCN提出之后，后续就是各路神仙打架了，都是针对GCN的各个不同点进行讨论改进了。

3.GAT：

​	本质上可以有两种运算方式，第一种是每一个顶点i都对图上任意顶点都进行attention运算。缺点是丢掉了图结构的这个特征

​	第二种是mask graph attention，注意力机制的运算只在邻居顶点上进行。

​	本质上而言：**GCN与GAT都是将邻居顶点的特征聚合到中心顶点上（一种aggregate运算），**利用graph上的local stationary学习新的顶点特征表达。**不同的是GCN利用了拉普拉斯矩阵（属于固定的卷积核），GAT利用attention系数。**一定程度上而言，GAT会更强，因为 顶点特征之间的相关性被更好地融入到模型中。但是捏GAT感觉对图结构的捕获不算特别好，它的两个重要的学习参数都跟图的结构无关，而GCN是一种全图的计算方式，**一次计算就更新全图的节点特征。学习的参数很大程度与图结构相关，这使得GCN在inductive任务上遇到困境。**

4.PPNP：

PPNP 的传播策略是从个性化 Pagerank 衍生而来的，作者利用图卷积网络(GCN)与PageRank的关系，提出了一种改进的基于个性化 PageRank 的传播方案。

之前我们提到了 GCN 的过平滑问题，有论文证明：节点的信息会以随机游走的方式向周围节点传递。假设消息传递了无穷层，那么这个随机游走分布将会收敛于一个稳定值，**即，获得的信息过分的global了，完全独立于根节点本身的信息。**

**personalized PageRank** （PPR）

PPR 的一大亮点就是能使用节点自身的特征信息，把根**节点自身的信息显式的加进来了：**

![image-20230607164437222](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230607164437222.png)

​	



​	图节点分类这种情况最好用一些inductive learning模型，例如GraphSAGE，这里假设你整个网络已经训练过了，图中所有节点的表示向量都是已知的。现在假设你输入了一个未知节点A，那么首先你得保证已知该节点与网络中其它节点的关系，比如节点A与网络中哪些节点有链接，链接权值多少等等。然后你就可以利用训练GraphSAGE时选择的聚合器直接聚合节点A邻居节点的表示向量来得到节点A的表示向量，然后将其输入到之前训练好的FNN+softmax中以得到具体的节点A的类别。

​	如果不使用inductive learning模型，而是使用类似于GCN之类的transductive learning模型，那么你就只能把节点A添加进网络后重新训练一遍了。



### KGC/TKGC(如果能和大模型融合的)

 GenKGC [99] 以大型语言模型 BART [5] 作为基础模型。借鉴 GPT-3 [60] 中使用的上下文学习方法，其中模型连接相关样本以学习正确输出答案，GenKGC 提出了一种关系引导的示例技术，包括具有相同关系的三元组，以促进模型的学习过程。此外，在生成过程中，提出了一种实体感知的分层解码方法以降低时间复杂度。KGT5 [151] 引入了一种新颖的 KGC 模型，满足了这类模型的四个关键要求：可扩展性、质量、多样性和简单性。为了实现这些目标，所提出的模型采用了简单的 T5 小型架构。该模型与以前的 KGC 方法不同，因为它是随机初始化的，而不是使用预训练模型。KG-S2S [152] 是一个综合框架，可应用于各种类型的 KGC 任务，包括静态 KGC、时间 KGC 和小样本 KGC。为实现这一目标，KG-S2S 通过引入一个额外的元素，将标准的三元组 KG 事实重塑为四元组（ h , r , t , m ） （h,r,t,m）（*h*,*r*,*t*,*m*），其中 m m*m* 代表额外的“条件”元素。虽然不同的 KGC 任务可能涉及不同的条件，但它们通常具有类似的文本格式，这使得在不同的 KGC 任务之间实现统一。KG-S2S 方法结合了各种技术，如实体描述、软提示和 Seq2Seq Dropout，以提高模型的性能。此外，它还利用约束解码确保生成的实体是有效的。对于闭源 LLM（例如 ChatGPT 和 GPT-4），AutoKG 采用提示工程来设计定制提示 [96]。如图 20 所示，这些提示包含任务描述、小样本示例和测试输入，指导 LLM 预测 KG 完成的尾实体。

大模型如何和外部知识库实体对齐？

​	传统的kgqa实体对齐已经相对成熟，但是需要大量训练，甚至需要建立同义词表，**别名词表**等等。此外首先需要命名实体识别（但是大模型对比较偏门的领域命名实体识别效果没那么好）

​	似乎大名鼎鼎的greaseLM也没有解决此问题。